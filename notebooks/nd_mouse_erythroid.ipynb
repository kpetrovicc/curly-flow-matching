{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nd Mouse Erythroid\n",
    "\n",
    "This notebook runs mouse erythroid experiments in n-dimensional case for reproducing results for $d=20$ and $d=50$\n",
    "\n",
    "In this notebook we implement OT-CFM and Curly-FM and compute metrics on held-out marginal.\n",
    "\n",
    "Mouse erythroid cells follow a curved developmental trajectory over time. We show that Curly-FM can recover these trajectories using RNA velocity priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import torch\n",
    "import torchsde\n",
    "from torchdyn.core import NeuralODE\n",
    "from tqdm import tqdm\n",
    "import anndata as ad\n",
    "import pandas as pd\n",
    "import scvelo as scv\n",
    "import torch\n",
    "\n",
    "from torchcfm import optimal_transport\n",
    "from torchcfm.conditional_flow_matching import *\n",
    "from torchcfm.models import MLP\n",
    "from torchcfm.utils import plot_trajectories, torch_wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cell data\n",
    "adata = sc.read_h5ad(\"../data/Erythroid/cells.h5ad\") # add file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.pca(adata, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obsm[\"X_velocity\"] = adata.layers[\"velocity\"] @adata.varm[\"PCs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 20\n",
    "hvgs = dim\n",
    "data = torch.tensor(adata.obsm[\"X_pca\"][:, :hvgs])\n",
    "velocity = torch.tensor(\n",
    "    adata.obsm[\"X_velocity\"][:, :hvgs]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_times = 3\n",
    "k=30\n",
    "latent = adata.obs[\"latent_time\"].to_numpy(float)\n",
    "edges = np.quantile(latent, np.linspace(0, 1, num_times + 1))\n",
    "bin_id = np.digitize(latent, edges[1:-1], right=False)\n",
    "adata.obs[\"stage3\"] = pd.Categorical(bin_id, categories=[0, 1, 2], ordered=True) \n",
    "coords = data\n",
    "coords = (coords - coords.mean(axis=0)) / coords.std(axis=0)\n",
    "\n",
    "bin_idx = torch.tensor(adata.obs[\"stage3\"].cat.codes.values, dtype=torch.long)\n",
    "\n",
    "positions  = [ data[bin_idx == i] for i in range(num_times) ]\n",
    "velocities = [ velocity[bin_idx == i] for i in range(num_times) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ts = [0, 2]\n",
    "test_ts = [1]\n",
    "\n",
    "x_train, v_train = [], []\n",
    "x_test, v_test = [], []\n",
    "\n",
    "for t in range(num_times):\n",
    "    if t in train_ts:\n",
    "        x_train.append(positions[t])\n",
    "        v_train.append(velocities[t])\n",
    "    elif t in test_ts:\n",
    "        x_test.append(positions[t])\n",
    "        v_test.append(velocities[t])\n",
    "        \n",
    "x_train = np.stack(x_train)\n",
    "v_train = np.stack(v_train)\n",
    "x_test = np.stack(x_test)\n",
    "v_test = np.stack(v_test)\n",
    "\n",
    "print(x_train.shape, v_train.shape)\n",
    "print(x_test.shape, v_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "\n",
    "stages = adata.obs[\"stage3\"]                     \n",
    "palette = sns.color_palette(\"husl\", stages.nunique())\n",
    "lut     = {str(k): v for k, v in zip(stages.cat.categories, palette)}\n",
    "\n",
    "colours = stages.astype(str).map(lut).to_numpy()\n",
    "\n",
    "def plot_trajectories(traj, legend=True):\n",
    "    n = 2000\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "    ax.scatter(\n",
    "        adata.obsm[\"X_pca\"][:, 0],\n",
    "        adata.obsm[\"X_pca\"][:, 1],\n",
    "        c=colours,\n",
    "        s=4,\n",
    "        alpha=1,\n",
    "    )\n",
    "\n",
    "    ax.scatter(traj[:, :n, 0], traj[:, :n, 1], s=0.4, alpha=0.05, c=\"olive\")\n",
    "    variable_h = len(traj) // 2\n",
    "    ax.scatter(traj[variable_h, :n, 0], traj[variable_h, :n, 1], s=4, alpha=1, c=\"orange\")\n",
    "    ax.scatter(traj[-1, :n, 0], traj[-1, :n, 1], s=4, alpha=1, c=\"blue\")\n",
    "\n",
    "    for i in range(15):\n",
    "        ax.plot(traj[:, i, 0], traj[:, i, 1], alpha=0.9, c=\"red\")\n",
    "    if legend:\n",
    "        plt.legend([r\"$p_0$\", r\"$p_t$\", r\"$p_1$\", r\"$X_t \\mid X_0$\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ut_knn_gaussian(\n",
    "    xt: torch.Tensor,  \n",
    "    x0: torch.Tensor,  \n",
    "    x1: torch.Tensor,  \n",
    "    v0: torch.Tensor,  \n",
    "    v1: torch.Tensor,  \n",
    "    k: int = 100,\n",
    "    eps: float = 1e-12,\n",
    "):\n",
    "    x = torch.cat([x0, x1], dim=0)\n",
    "    v = torch.cat([v0, v1], dim=0)\n",
    "\n",
    "    dists = torch.cdist(xt, x)\n",
    "\n",
    "    knn_dists, knn_idx = torch.topk(dists, k=k, dim=1, largest=False)\n",
    "\n",
    "    h = knn_dists[:, -1:].clamp_min(eps)  \n",
    "    w = torch.exp(-(knn_dists**2) / (2 * h**2))  \n",
    "    w = w / (w.sum(dim=1, keepdim=True) + eps)  \n",
    "\n",
    "    v_knn = v[knn_idx]  \n",
    "    v_xt = (w.unsqueeze(-1) * v_knn).sum(dim=1) * 1\n",
    "    \n",
    "    distance_factor = knn_dists[:, :1]\n",
    "    w = 100\n",
    "    dist_thresh = 0.2\n",
    "    distance_factor = (torch.nn.functional.sigmoid((distance_factor - dist_thresh) * w) / 2) + 0.5\n",
    "    noise_vector = torch.randn_like(v_xt) * 0.01\n",
    "    v_xt = (1 - distance_factor) * v_xt + distance_factor * noise_vector\n",
    "    return v_xt, knn_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(FM_module, X, batch_size, n_times, ts_train, return_noise=False):\n",
    "    \"\"\"Construct a batch with point sfrom each timepoint pair\"\"\"\n",
    "    ts = []\n",
    "    xts = []\n",
    "    uts = []\n",
    "    noises = []\n",
    "    for t_start in range(len(ts_train) - 1):      \n",
    "        t_end = t_start + 1\n",
    "        \n",
    "        x0 = (\n",
    "            torch.from_numpy(\n",
    "                X[t_start][np.random.randint(X[t_start].shape[0], size=batch_size)]\n",
    "            )\n",
    "            .float()\n",
    "            .to(device)\n",
    "        )    \n",
    "        x1 = (\n",
    "            torch.from_numpy(\n",
    "                X[t_end][np.random.randint(X[t_end].shape[0], size=batch_size)]\n",
    "            )\n",
    "            .float()\n",
    "            .to(device)\n",
    "        )\n",
    "        \n",
    "        if return_noise:\n",
    "            t, xt, ut, eps = FM_module.sample_location_and_conditional_flow(\n",
    "                x0, x1, return_noise=return_noise\n",
    "            )\n",
    "            noises.append(eps)\n",
    "        else:\n",
    "            t, xt, ut = FM_module.sample_location_and_conditional_flow(\n",
    "                x0, x1, return_noise=return_noise\n",
    "            )\n",
    "            \n",
    "        ts.append(t + t_start)\n",
    "        xts.append(xt)\n",
    "        uts.append(ut)\n",
    "        \n",
    "    t = torch.cat(ts)\n",
    "\n",
    "    xt = torch.cat(xts)\n",
    "    ut = torch.cat(uts)\n",
    "    if return_noise:\n",
    "        noises = torch.cat(noises)\n",
    "        return t, xt, ut, noises\n",
    "    return t, xt, ut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CurlyWrapperWithMetrics(torch.nn.Module):\n",
    "    def __init__(self, model, x0, x1, v0, v1, k):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.x0 = x0\n",
    "        self.x1 = x1\n",
    "        self.v0 = v0\n",
    "        self.v1 = v1\n",
    "        self.k = k\n",
    "\n",
    "    def forward(self, t, z, *args, **kwargs):\n",
    "        x = z[:, :-2]\n",
    "        x_dot = self.model(torch.cat([x, t.repeat(x.shape[0])[:, None]], dim=1))\n",
    "\n",
    "        u_t, _ = get_ut_knn_gaussian(\n",
    "            x,\n",
    "            self.x0,\n",
    "            self.x1,\n",
    "            self.v0,\n",
    "            self.v1,\n",
    "            k=self.k,\n",
    "        )\n",
    "\n",
    "        cos_dist = 1 - F.cosine_similarity(u_t, x_dot, dim=1)\n",
    "        L2_squared = torch.sum((u_t - x_dot) ** 2, dim=1)\n",
    "\n",
    "        return torch.cat([x_dot, cos_dist.unsqueeze(1), L2_squared.unsqueeze(1)], dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OT-CFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "sigma = 0.01\n",
    "ot_cfm_model = MLP(dim=dim, time_varying=True, w=128).to(device)\n",
    "ot_cfm_optimizer = torch.optim.Adam(ot_cfm_model.parameters(), 1e-4)\n",
    "FM = ExactOptimalTransportConditionalFlowMatcher(sigma=sigma)\n",
    "print(k, num_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_otcfm = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in tqdm(range(3000)):\n",
    "    ot_cfm_optimizer.zero_grad()\n",
    "    t, xt, ut = get_batch(FM, x_train, batch_size, num_times, train_ts)\n",
    "    vt = ot_cfm_model(torch.cat([xt, t[:, None]], dim=-1))\n",
    "    loss = torch.mean((vt - ut) ** 2)\n",
    "    loss.backward()\n",
    "    ot_cfm_optimizer.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        loss_otcfm.append(loss.cpu().item())\n",
    "        \n",
    "end_time = time.time()\n",
    "\n",
    "train_time_ot_cfm = end_time - start_time\n",
    "\n",
    "plt.plot(loss_otcfm)\n",
    "plt.grid(alpha=0.2)\n",
    "plt.xlabel(\"Iteration / 100\")\n",
    "plt.ylabel(\"Loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    wass1, cos_dist, L2_cost = [], [], []\n",
    "    for t, t_train in enumerate(train_ts[:-1]):\n",
    "        x0 = positions[t_train].float().to(device)\n",
    "        x1 = positions[t_train + 1].float().to(device)\n",
    "        v0 = velocities[t_train].float().to(device)\n",
    "        v1 = velocities[t_train + 1].float().to(device)\n",
    "\n",
    "        wrapped_model = CurlyWrapperWithMetrics(ot_cfm_model, x0, x1, v0, v1, k)\n",
    "        node = NeuralODE(wrapped_model, solver=\"euler\", sensitivity=\"adjoint\")\n",
    "\n",
    "        z0 = torch.cat([x0, torch.zeros(x0.shape[0], 2, device=x0.device)], dim=1)\n",
    "\n",
    "        pred_out = node.trajectory(\n",
    "            z0.to(device),\n",
    "            t_span=torch.linspace(t, t + 1 / 2, 100),\n",
    "        ).cpu()\n",
    "\n",
    "        pred_traj = pred_out[:, :, :-2]\n",
    "        cosine_traj = pred_out[:, :, -2]\n",
    "        L2_traj = pred_out[:, :, -1]\n",
    "\n",
    "        pred = pred_traj[-1]\n",
    "\n",
    "        cos_dist.append(cosine_traj[-1].cpu().mean())\n",
    "        L2_cost.append(L2_traj[-1].cpu().mean())\n",
    "\n",
    "        print(L2_traj[-1].cpu().mean())\n",
    "\n",
    "        wass1.append(optimal_transport.wasserstein(pred, x1.cpu(), power=1))\n",
    "\n",
    "    cos_dist = np.stack(cos_dist)\n",
    "    L2_cost = np.stack(L2_cost)\n",
    "\n",
    "    print(\"Avg Cosine distance: \", np.mean(cos_dist))\n",
    "    print(\"Avg L2 cost: \", np.mean(L2_cost))\n",
    "\n",
    "    wass1 = np.stack(wass1)\n",
    "    print(\"Avg Wass-2 distance: \", np.mean(wass1))\n",
    "    \n",
    "    print()\n",
    "    print(\"----------------------\")\n",
    "    print()\n",
    "    print(\"t            Cosine-dist    &      L2 cost       &       Wass-2 \")\n",
    "    for i, t_left_out in enumerate([\"t2\"]):  \n",
    "        print(\n",
    "            t_left_out + f\" --- {cos_dist[i]} & {L2_cost[i]} & {wass1[i]} \\\\\\\\\"\n",
    "        )\n",
    "    \n",
    "    minutes = int(train_time_ot_cfm // 60)\n",
    "    seconds = int(train_time_ot_cfm % 60)\n",
    "\n",
    "    print()\n",
    "    print(f\"OT-CFM training time -- {minutes}:{seconds} (mins:secs)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.func import vmap\n",
    "import scipy\n",
    "def get_xt(t, t_start, x0, x1, geodesic_model, sigma=0.0):\n",
    "    mu_t = (1 - t) * x0 + t * x1 +  t * (1-t) * (geodesic_model(torch.cat([x0, x1, t+t_start], dim=-1)))\n",
    "    epsilon = torch.randn_like(x0)\n",
    "    x_t = mu_t + torch.sqrt(t*(1-t))*sigma * epsilon\n",
    "    return mu_t, x_t, epsilon\n",
    "\n",
    "def get_xt_xt_dot(t, t_start, t_end, x0, x1, geodesic_model, sigma=0.0):\n",
    "    # get xt and xt dot from the geodesic model\n",
    "    with torch.enable_grad():\n",
    "        t = t[..., None]\n",
    "        t.requires_grad_(True)\n",
    "        #mu_t, xt, eps = NEW_get_xt(t, t_start, t_end, x0, x1, geodesic_model, sigma=sigma)\n",
    "        mu_t, xt, eps = get_xt(t, t_start, x0, x1, geodesic_model, sigma=sigma)\n",
    "        mu_t_dot_list = []\n",
    "        for i in range(xt.shape[-1]):\n",
    "            mu_t_dot_list.append(\n",
    "                torch.autograd.grad(torch.sum(mu_t[..., i]), t, create_graph=True)[0]\n",
    "            )\n",
    "        # this is velocity (euclidean metric)\n",
    "        mu_t_dot = torch.cat(mu_t_dot_list, -1)\n",
    "    return xt, mu_t_dot, eps\n",
    "\n",
    "def coupling_geo_new(\n",
    "    t_start, t_end, x0, x1, x0s, x1s, v0s, v1s, geodesic_model, k, sigma\n",
    "):\n",
    "    batch_size, d = x0.shape\n",
    "\n",
    "    t = torch.rand(1).type_as(x0) * torch.ones((batch_size, batch_size), device=x0.device)\n",
    "    x0_r = x0.repeat(batch_size, 1, 1)\n",
    "    x1_r = x1.repeat(batch_size, 1, 1).transpose(0, 1)\n",
    "    xt, mu_t_dot, eps = get_xt_xt_dot(\n",
    "        t, t_start, t_end, x0_r, x1_r, geodesic_model, sigma\n",
    "    )\n",
    "\n",
    "    ut = vmap(lambda x: get_ut_knn_gaussian(x, x0s, x1s, v0s, v1s, k=k)[0], randomness=\"different\")(xt)\n",
    "\n",
    "    L2_cost = 0.5 * ((mu_t_dot.detach() - ut) ** 2).sum(-1)\n",
    "    _, j = scipy.optimize.linear_sum_assignment(L2_cost.detach().cpu().numpy())\n",
    "\n",
    "    pi_x0 = x0[j]\n",
    "    pi_x1 = x1\n",
    "\n",
    "    return pi_x0, pi_x1, eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_geo(geo, X, V, batch_size, sigma, ts_train):\n",
    "    \"\"\"Construct a batch with point sfrom each timepoint pair\"\"\"\n",
    "    ts = []\n",
    "    t_orig_list = []\n",
    "    mu_t_dots = []\n",
    "    eps_list = []\n",
    "    xts = []\n",
    "    uts = []\n",
    "    dists = []\n",
    "    for t_start in range(len(ts_train) - 1):\n",
    "        t_end = t_start + 1\n",
    "        \n",
    "        idcs_0 = np.random.randint(X[t_start].shape[0], size=batch_size)\n",
    "        idcs_1 = np.random.randint(X[t_end].shape[0], size=batch_size)\n",
    "\n",
    "        x0 = torch.from_numpy(X[t_start][idcs_0]).float().to(device)\n",
    "        x1 = torch.from_numpy(X[t_end][idcs_1]).float().to(device)\n",
    "\n",
    "        v0 = torch.from_numpy(V[t_start][idcs_0]).float().to(device)\n",
    "        v1 = torch.from_numpy(V[t_end][idcs_1]).float().to(device)\n",
    "    \n",
    "        t = torch.rand(x0.shape[0]).type_as(x0) \n",
    "        t_o = t\n",
    "        \n",
    "        xt, mu_t_dot, eps = get_xt_xt_dot(t, t_start, t_end, x0, x1, geo, sigma=sigma)\n",
    "        ut, dist = get_ut_knn_gaussian(\n",
    "            xt,\n",
    "            x0,\n",
    "            x1,\n",
    "            v0,\n",
    "            v1,\n",
    "            k=k,\n",
    "        )\n",
    "        xt = xt + torch.sqrt(t* (1-t)).unsqueeze(1) * sigma * eps\n",
    "        \n",
    "        t_orig_list.append(t_o)\n",
    "        ts.append(t + t_start)\n",
    "        xts.append(xt)\n",
    "        uts.append(ut)\n",
    "        mu_t_dots.append(mu_t_dot)\n",
    "        eps_list.append(eps)\n",
    "        dists.append(dist)\n",
    "    \n",
    "    t_orig = torch.cat(t_orig_list)\n",
    "    t = torch.cat(ts)\n",
    "    xt = torch.cat(xts)\n",
    "    ut = torch.cat(uts)\n",
    "    mu_t_dot = torch.cat(mu_t_dots)\n",
    "    eps = torch.cat(eps_list)\n",
    "    dist = torch.cat(dists)\n",
    "\n",
    "    return t_orig, t, xt, ut, mu_t_dot, eps, dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "sigma = 0.01\n",
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_model = MLP(dim=dim*2, out_dim=dim, time_varying=True, w=256).to(device)\n",
    "geo_optimizer = torch.optim.AdamW(geo_model.parameters(), 1e-4)\n",
    "\n",
    "train_loss = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in tqdm(range(3_000)):\n",
    "    geo_optimizer.zero_grad()\n",
    "    t_orig, t, xt, ut, mu_t_dot, eps, knn_dist = get_batch_geo(geo_model, x_train, v_train, batch_size, sigma, train_ts)\n",
    " \n",
    "    hinge_value = 0.1\n",
    "    knn_dist[knn_dist < hinge_value] = hinge_value\n",
    "    knn_loss = torch.mean(knn_dist)\n",
    "\n",
    "    cosine_loss = 1 - torch.nn.functional.cosine_similarity(ut, mu_t_dot).mean()\n",
    "    loss = 1 * torch.mean((alpha*ut - mu_t_dot) ** 2) + 0*cosine_loss + 0 * 0*knn_loss\n",
    "    \n",
    "    loss.backward()\n",
    "    geo_optimizer.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        train_loss.append(loss.cpu().item())\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "train_time_curly_geo = end_time - start_time\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.grid(alpha=0.2)\n",
    "plt.xlabel(\"Iteration / 100\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_vel(geo, X, V, batch_size, sigma, ts_train):\n",
    "    \"\"\"Construct a batch with point sfrom each timepoint pair\"\"\"\n",
    "    ts = []\n",
    "    t_orig_list = []\n",
    "    mu_t_dots = []\n",
    "    eps_list = []\n",
    "    xts = []\n",
    "    for t_start in range(len(ts_train) - 1):\n",
    "        t_end = t_start + 1\n",
    "\n",
    "        idcs_0 = np.random.randint(X[t_start].shape[0], size=batch_size)\n",
    "        idcs_1 = np.random.randint(X[t_end].shape[0], size=batch_size)\n",
    "\n",
    "        x0 = torch.from_numpy(X[t_start][idcs_0]).float().to(device)\n",
    "        x1 = torch.from_numpy(X[t_end][idcs_1]).float().to(device)\n",
    "\n",
    "        v0 = torch.from_numpy(V[t_start][idcs_0]).float().to(device)\n",
    "        v1 = torch.from_numpy(V[t_end][idcs_1]).float().to(device)\n",
    "\n",
    "        t = torch.rand(x0.shape[0]).type_as(x0)\n",
    "        t_o = t\n",
    "\n",
    "        x0, x1, _ = coupling_geo_new(t_start, t_end, x0, x1, x0, x1, v0, v1, geo, k, sigma=sigma)\n",
    "        xt, mu_t_dot, eps = get_xt_xt_dot(t, t_start, t_end, x0, x1, geo, sigma=sigma)\n",
    "\n",
    "        t_orig_list.append(t_o)\n",
    "        ts.append(t + t_start)\n",
    "        xts.append(xt)\n",
    "        mu_t_dots.append(mu_t_dot)\n",
    "        eps_list.append(eps)\n",
    "\n",
    "    t_orig = torch.cat(t_orig_list)\n",
    "    t = torch.cat(ts)\n",
    "    xt = torch.cat(xts)\n",
    "    mu_t_dot = torch.cat(mu_t_dots)\n",
    "    eps = torch.cat(eps_list)\n",
    "\n",
    "    return t_orig, t, xt, mu_t_dot, eps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "sigma = 0.01\n",
    "alpha = 1.0\n",
    "vel_model = MLP(dim=dim, time_varying=True, w=256).to(device).to(device)\n",
    "vel_optimizer = torch.optim.Adam(vel_model.parameters(), 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_loss = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in tqdm(range(3000)):\n",
    "    vel_optimizer.zero_grad()\n",
    "    \n",
    "    t_orig, t, xt, mu_t_dot, eps = get_batch_vel(geo_model, x_train, v_train, batch_size, sigma, train_ts)\n",
    "    vt = vel_model(torch.cat([xt.detach(), t[:, None]], dim=-1))\n",
    "    \n",
    "    loss = torch.mean((vt - mu_t_dot.detach()) ** 2)\n",
    "\n",
    "    loss.backward() \n",
    "    vel_optimizer.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        #print(f\"Train loss: {loss:.4f} | Flow loss: {loss:.4f}\")\n",
    "        vel_loss.append(loss.cpu().item())\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "train_time_curly_vel = end_time - start_time\n",
    "\n",
    "plt.plot(vel_loss)\n",
    "plt.grid(alpha=0.2)\n",
    "plt.xlabel(\"Iteration / 100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    wass1, cos_dist, L2_cost = [], [], []\n",
    "    for t, t_train in enumerate(train_ts[:-1]):\n",
    "        x0 = positions[t_train].float().to(device)\n",
    "        x1 = positions[t_train + 1].float().to(device)\n",
    "        v0 = velocities[t_train].float().to(device)\n",
    "        v1 = velocities[t_train + 1].float().to(device)\n",
    "\n",
    "        wrapped_model = CurlyWrapperWithMetrics(vel_model, x0, x1, v0, v1, k)\n",
    "        node = NeuralODE(wrapped_model, solver=\"euler\", sensitivity=\"adjoint\")\n",
    "\n",
    "        z0 = torch.cat([x0, torch.zeros(x0.shape[0], 2, device=x0.device)], dim=1)\n",
    "\n",
    "        pred_out = node.trajectory(\n",
    "            z0.to(device),\n",
    "            t_span=torch.linspace(t, t + 1 / 2, 100),\n",
    "        ).cpu()\n",
    "\n",
    "        pred_traj = pred_out[:, :, :-2]\n",
    "        cosine_traj = pred_out[:, :, -2]\n",
    "        L2_traj = pred_out[:, :, -1]\n",
    "\n",
    "        pred = pred_traj[-1]\n",
    "\n",
    "        cos_dist.append(cosine_traj[-1].cpu().mean())\n",
    "        L2_cost.append(L2_traj[-1].cpu().mean())\n",
    "\n",
    "        print(L2_traj[-1].cpu().mean())\n",
    "\n",
    "        wass1.append(optimal_transport.wasserstein(pred, x1.cpu(), power=1))\n",
    "\n",
    "    cos_dist = np.stack(cos_dist)\n",
    "    L2_cost = np.stack(L2_cost)\n",
    "\n",
    "    print(\"Avg Cosine distance: \", np.mean(cos_dist))\n",
    "    print(\"Avg L2 cost: \", np.mean(L2_cost))\n",
    "\n",
    "    wass1 = np.stack(wass1)\n",
    "    print(\"Avg Wass-2 distance: \", np.mean(wass1))\n",
    "\n",
    "    print()\n",
    "    print(\"----------------------\")\n",
    "    print()\n",
    "    print(\"t            Cosine-dist    &      L2 cost       &       Wass-2 \")\n",
    "    for i, t_left_out in enumerate([\"t2\"]):\n",
    "        print(t_left_out + f\" --- {cos_dist[i]} & {L2_cost[i]} & {wass1[i]} \\\\\\\\\")\n",
    "\n",
    "    train_time_curly = train_time_curly_geo + train_time_curly_vel\n",
    "    minutes = int(train_time_curly // 60)\n",
    "    seconds = int(train_time_curly % 60)\n",
    "\n",
    "    print()\n",
    "    print(f\"Curly training time -- {minutes}:{seconds} (mins:secs)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curlyfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
